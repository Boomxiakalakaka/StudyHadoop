声音、画面都ok吧
好的，我这ok

然后有问题的可以在上课之前问一问

分区器会对kv的分布造成影响，会对最终的运算时间有影响吗？
分区器决定每个kv去往哪个reduce；
比如：如果默认用HashPartitioner，那么每个reduce task处理的数据有可能是均匀的；
然后，自定义分区器后，造成某些reduce task拉取的数据更多，相应的是会有影响

idea就是一个编程工具
学习idea的一些常用的快捷键
maven怎么与idea配置

老师maptask里也是有排序的是吧
是的；在map、reduce阶段，都会对kv对，按照key进行排序

xxzx_6227465 19:55:21
老师，上节课没听，影响这节课吗
可能会

xxzx_6227465 19:56:02
排序是第四步？
对

上节课的代码，自己有没有敲一遍？

汪志良 19:56:50
没有问题就是最大的问题。 
如果说不知道从何问起的话，那么久先把课堂上的东西消化了


小明同学 19:57:24
不是说要布置点小案例嘛 

汪志良 19:59:23
setMaxInputSplitSize设置4M 两个1M的文件怎么虚拟存储？
=======================

top1
现在需要求取每个订单当中金额最大的商品
首先一点：
要求每个每个订单当中金额最大的商品，是不是得将每个订单的所有的记录，传入到一个reduce当中
	分区的逻辑 getPartiton
每个订单当中金额最大的商品
	是不是可以将商品，定义个javabean
		排序：同一个订单中，金额大的排在前边，就是降序排序
要求取每个订单当中金额最大的商品
	每个reduce task中，可能回去不同订单的数据，需要将同一订单的kv作为一组
		自定义分组决定
mapper读文件
Order_0000003	Pdt_01	222.8
key：javabean
value：不关心，所以可以用nullWritable

林同学 20:29:39
源数据万一有错这样写就空指针啦 
可以让程序健壮一些，做些判断
	
歸壹 20:38:29
分组后reduce任务个数不变吗 
reduce个数由谁决定？默认多少个？
job.setNumReduceTasks(3)

梁江涛 20:39:06
本地运行不设置分区也可以吧，就一个分区 
设置为多个reduce task

Hengrui 20:41:08
请问老师那我要是在reduce里想反回第二大的或者是返回最大的两个时这个reduce该怎么写呢? 
没预习吧

赫赫哈嘿 20:43:35
这么简单的需求用mapreduce做，好繁琐啊 
吃透分组即可

梁江涛 20:52:36
values迭代的时候为啥key也会变化，一个方法中 
因为：mr框架，中key，value复用了一个对象

段宁建--大数据五期 20:53:46
问一下分割values是对整个文件数据分割 还是怎么的 
map 


农夫三拳 20:54:10
没指定文件名，多个文件全读吗 
如果指定了路径，会把路径下的所有文件作为输入；不会递归

Hengrui 20:54:46
reduce 方法里key的输入能变成Iterable 么? 
不能
这是人家mr框架，开发的时候，就这样
除非进行hadoop源码的修改，二次开发；没有必要

梁江涛 20:56:26
我刚才debug了一下，key确实在迭代的时候变化了 
一般人发现不了


蒋子杰 20:56:37
感觉都能听懂 自己想又是另外一回事
下去多练习

林崇辉 21:15:11
如果不指定到具体的文件，只指定到目录的话，会生成多少个文件？ 
reduce输出吗？
每个reduce task默认是生成一个输出文件
除非进行了OutputFormat的自定义

歸壹 21:15:48
集群运行错误信息在哪里看


蒋子杰 21:16:43
设置了多个reduetask 结果是不是都一样 
对
试一下



农夫三拳 21:18:54
reduce task和节点数有关系吗？
没有关系
你想：服务器可能256G内存，cpu上百核， 所以它上边可以运行上百甚至上千个task

林泽斌 21:19:49
刚刚订单那个例子的分组和分区的区别我不是很懂。我可以这么理解吗？map前按订单编号分区，reduce前再按订单编号分组？ 

四九 21:19:50
老师这些例子都可以拿sql实现，那么hadoop实际生产应用场景能举个例子吗？
离线计算
	mr做数据的清洗
	还有一些其他的一些常规的业务

编程模型中的1~8已经学完了

接下来我们看一下map、reduce运行的时候，具体的细节是什么？


map、reduce逻辑，参考一下《hadoop权威指南 第四版》 shuffle的过程

胖虎ヾ 21:51:56
分组后数据保存在哪呢、 
每组数据，调用reduce方法之前，会保存在内存中

xxzx_7196030 21:53:06
大概听懂了，具体还要有空研究， 
需要反复的复习
一个比较好的方式，自己手绘一遍

赫赫哈嘿 21:57:05
如果是yarn运行mapreduce的话，mapreduce阶段产生的临时文件是存放在本地磁盘上还是HDFS上 
map阶段的中间文件，是写到本地磁盘
reduce阶段是HDFS（）
/中间文件
当mr执行完成后，会自动被删除

自定义分组
	类 extends WritableComparator {
		构造方法{
			super(key.class, true)
		}
	
		compare(o1, o2) {
		}
	}
outputformat
	自定义类 extends OutputFormat
	RecordWriter -> write()
	
map reduce的原理
map输出到reduce 调用reduce()之前，这部分，一般称为shuffle
压缩
自定义计数器

小明同学 22:10:20
snappy压缩后生成的文件也是这种格式的，我们怎么解压缩，查看数据呢 
怎么解压呢？mr读取文件的时候，根据文件后缀，.snappy，自动选择对应的压缩算法进行解压缩


小明同学 22:25:19
计数器只能统计一个map task中的吧，如果是多个map task ，要累加吧
进行累加
就是统计多个
自动累加


林同学 22:25:30
map到reduce之前不是都是在内存里么 然而中间文件又是在磁盘 
不是

赫赫哈嘿 22:28:55
LZO压缩是不是需要额外安装？
默认支持




 












	
	







	


