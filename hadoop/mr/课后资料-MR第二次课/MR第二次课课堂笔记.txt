声音、画面ok的话，回1
我这边是OK的

说一下，MR和yarn的课件，写在一个word里，mr第一次时，已经发给大家了

行哲 19:50:59
编码这些都必须掌握吗
是的，肯定得编码得过关

杨章云 19:52:50
Job.getInstance(super.getConf(),"FlowCount"); super.getConf()就一个空对象，不太理解 


xxzx_9958089 19:57:09
老师可以用eclipse吗
可以

林志华 19:57:27
一个文件做MR词频统计，这个文件被分成两个block，如果一个词被分到两个block，那这个咋办？
这个不会
有一个record边界

===================
八步走

map阶段：
第一步：通过InputFormat读取分片数据，生成k1,v1，传入下一步
第二步：自定义mapper类的逻辑,map()，接受k1,v1,处理之后，生成k2,v2

shuffle阶段：
第三步：分区；相同key去往相同的分区，同一个分区的数据，去往同一个reduce task
第四步：排序；每个分区中的kv对，进行排序
第五步：本地规约combiner 减少产生的中间数据；减少map到reduce间的传输的数据量
第六步：分组 在一个reduce task中，相同组的kv对们，调用一次reduce()

reduce阶段：
第七步：自定义reduce逻辑，接受k2,v2，处理后生成k3,v3
第八步：使用OutputFormat将k3,v3输出保存起来

==========
如果大量的小文件不合并的话，会怎么样？
1kb 小文件-》1 block -》 1 split -》 一个map task
jvm -》t1; 计算-》t2

xzxx_6786265 20:10:30
很多碎片 浪费空间 

哲程是大腿😘 20:10:35
namenode 内存 

段宁建--大数据五期 20:10:49
nn的内存 

FileInputFormat
public List<InputSplit> getSplits(JobContext job) throws IOException {

Math.max(minSize, Math.min(maxSize, blockSize)); => 128M

file1.txt    300M
file2.txt    10M
4个分片

如何控制mapTask的个数
通过改变分片的大小即可；
变大的话，map task个数变少
反之，变多

如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。
9m > 2* 4
4
5m < 8 => 2.5M 2.5M

✨卡米✨ 20:36:57
为什么最终切片可以大于设定的4M?
主要是理解：
1、切分虚拟存储文件
2、根据规则，生成切片

林同学 20:52:05
晕了 

====
har
写sequencefile文件

Eric Song 21:32:52
input 下多个文件，读取的流程不是很明白，能讲解下吗？ 
3个文件-》 3 split -》 3个map task

Eric Song 21:33:14
或者说文件加载的过程？ 


===========
map阶段：
第一步：通过InputFormat读取分片数据，生成k1,v1，传入下一步
第二步：自定义mapper类的逻辑,map()，接受k1,v1,处理之后，生成k2,v2

shuffle阶段：
第三步：分区；相同key去往相同的分区，同一个分区的数据，去往同一个reduce task
第四步：排序；每个分区中的kv对，进行排序
第五步：本地规约combiner 减少产生的中间数据；减少map到reduce间的传输的数据量
第六步：分组 在一个reduce task中，相同组的kv对们，调用一次reduce()

reduce阶段：
第七步：自定义reduce逻辑，接受k2,v2，处理后生成k3,v3
第八步：使用OutputFormat将k3,v3输出保存起来

第一步：done
第二步：done

shuffle阶段：
第三步：分区
  public int getPartition(K key, V value,
                          int numReduceTasks) {
    return (key.hashCode() & Integer.MAX_VALUE) % numReduceTasks;
  }
  
  numReduceTasks = 4
  getPartition（） =》 0,1,2,3
  
思考：如果手动指定6个分区，reduceTask个数设置为3个会出现什么情况
如果手动指定6个分区，reduceTask个数设置为9个会出现什么情况
自己试验一下

mr中的key有可排序性的特点；可序列化


=====
第四步：done 排序
mr中有时候，需要按照key做几种排序规则；
先按照key中的某一个值（属性）进行排序；如果相同，在按照另外一个属性进行排序

二次排序
自定义一个java bean 作为key extends WritableComparable<Key>
能够比较、序列化

WritableComparable<T> extends Writable, Comparable

第五步：本地规约combiner


从一到五已经讲完了 

东方甲乙木 22:12:11
我觉得得边看资料边看视频，然后自己记笔记，画思维导图，然后多敲代码多实践 
自己经常总结

sinc 22:20:03
相当于这几步算是 性能优化阶段？
第一步：框架没有满足要求的inputformat 自定义
mapper

分区：根据自己的业务逻辑，进行自定义
排序：根据自己的业务逻辑，进行自定义
combiner: 跟优化有关系

分组：根据自己的业务逻辑，进行自定义

东方甲乙木 22:23:18
老师能不能整一个MR的练习题合集，练练手 
可以

小明同学 22:24:34
在工作中排序的意义是的什么，老师 
排序的意义：首先这个框架默认就对key赋予了排序的特点
实际工作中，要你统计一下一年当中，所有人的总开销的排名 top10
	排序
	取头10个
	
select userid, sum(huaxiao) as hx from order group by userid order by hx

惠绒 22:26:02
刚二次排序是怎么定位到第3列排序的 
补一下java基础  
compareTo

Eric Song 22:26:24
在集群上运行mapReduce jar ， 不是很懂怎么执行的 
如果说是指的不知道这个map task、reduce task到底是如何分发到不同的计算节点并行执行的话
yarn会讲






  










